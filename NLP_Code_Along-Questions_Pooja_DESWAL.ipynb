{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Code Along questions\n",
    "\n",
    "For this code along we will build a spam filter!\n",
    "\n",
    "We'll use a classic dataset for this - UCI Repository SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and  read the dataset,  have Spark infer the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as funct\n",
    "spark = SparkSession.builder.appName('Spam_filter').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "| ham|I'm gonna be home...|\n",
      "|spam|SIX chances to wi...|\n",
      "|spam|URGENT! You have ...|\n",
      "| ham|I've been searchi...|\n",
      "| ham|I HAVE A DATE ON ...|\n",
      "|spam|XXXMobileMovieClu...|\n",
      "| ham|Oh k...i'm watchi...|\n",
      "| ham|Eh u remember how...|\n",
      "| ham|Fine if thats th...|\n",
      "|spam|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = spark.read.csv(\"SMSSpamCollection\", sep = \"\\t\", inferSchema=True, header = False)\n",
    "input_text.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = input_text.withColumnRenamed('_c0', 'class').withColumnRenamed('_c1', 'text')\n",
    "input_text.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = input_text.withColumn(\"length\", funct.length(\"text\"))\n",
    "input_text.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the groupy mean of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text.groupBy(\"class\").agg(funct.mean('length')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you transform you raw text in to tf_idf model :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chain the transformer Tokenizer, StopWordsRemover, CountVectorizer and IDF for text to have a final column name 'tf_idf'\n",
    "- use the transformer StringIndexer for class column into output column 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create feature with vector assembler 'tf_idf','length of as input columns into output column named 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use pipeline for fit and transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: it may differ for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                text|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|\n",
      "|  1.0|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|\n",
      "|  0.0|URGENT! You have ...|[urgent!, you, ha...|\n",
      "|  1.0|I've been searchi...|[i've, been, sear...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k...i'm, wat...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|\n",
      "|  1.0|Fine if thats th...|[fine, if, thats...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text.createOrReplaceTempView('temp')\n",
    "input_text = spark.sql('select case class when \"ham\" then 1.0  else 0 end as label, text from temp')\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "input_words = tokenizer.transform(input_text)\n",
    "input_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|               words|            Features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|(13587,[8,42,52,6...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|(13587,[5,75,411,...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|(13587,[0,3,8,20,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|(13587,[5,22,60,1...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|(13587,[0,1,66,87...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|(13587,[0,2,6,10,...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|(13587,[0,7,9,13,...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|(13587,[0,10,11,4...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|(13587,[0,2,3,14,...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|(13587,[0,4,5,10,...|\n",
      "|  1.0|I'm gonna be home...|[i'm, gonna, be, ...|(13587,[0,1,6,32,...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|(13587,[0,6,40,46...|\n",
      "|  0.0|URGENT! You have ...|[urgent!, you, ha...|(13587,[0,2,3,4,8...|\n",
      "|  1.0|I've been searchi...|[i've, been, sear...|(13587,[0,1,2,3,4...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|(13587,[1,3,14,16...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|(13587,[0,4,8,11,...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k...i'm, wat...|(13587,[158,314,3...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|(13587,[1,5,20,47...|\n",
      "|  1.0|Fine if thats th...|[fine, if, thats...|(13587,[4,5,29,59...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|(13587,[0,4,28,82...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer (inputCol=\"words\", outputCol=\"Features\")\n",
    "model = count.fit(input_words)\n",
    "data_features = model.transform(input_words)\n",
    "data_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|               words|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|(13587,[8,42,52,6...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|(13587,[5,75,411,...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|(13587,[0,3,8,20,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|(13587,[5,22,60,1...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|(13587,[0,1,66,87...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|(13587,[0,2,6,10,...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|(13587,[0,7,9,13,...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|(13587,[0,10,11,4...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|(13587,[0,2,3,14,...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|(13587,[0,4,5,10,...|\n",
      "|  1.0|I'm gonna be home...|[i'm, gonna, be, ...|(13587,[0,1,6,32,...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|(13587,[0,6,40,46...|\n",
      "|  0.0|URGENT! You have ...|[urgent!, you, ha...|(13587,[0,2,3,4,8...|\n",
      "|  1.0|I've been searchi...|[i've, been, sear...|(13587,[0,1,2,3,4...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|(13587,[1,3,14,16...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|(13587,[0,4,8,11,...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k...i'm, wat...|(13587,[158,314,3...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|(13587,[1,5,20,47...|\n",
      "|  1.0|Fine if thats th...|[fine, if, thats...|(13587,[4,5,29,59...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|(13587,[0,4,28,82...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import  IDF\n",
    "idf = IDF(inputCol=\"Features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(data_features)\n",
    "clean_data = idfModel.transform(data_features)\n",
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect spam or Ham\n",
    "\n",
    "now use your tf-idf data to classify spam and ham\n",
    "\n",
    "feel free to use any classifier model\n",
    "\n",
    "result may differ for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|               words|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  0.0|* FREE* POLYPHONI...|[*, free*, polyph...|(13587,[0,4,11,12...|\n",
      "|  0.0|**FREE MESSAGE**T...|[**free, message*...|(13587,[4,10,20,5...|\n",
      "|  0.0|+123 Congratulati...|[+123, congratula...|(13587,[0,4,5,8,1...|\n",
      "|  0.0|+123 Congratulati...|[+123, congratula...|(13587,[0,4,5,8,1...|\n",
      "|  0.0|+449071512431 URG...|[+449071512431, u...|(13587,[0,4,7,14,...|\n",
      "|  0.0|-PLS STOP bootyde...|[-pls, stop, boot...|(13587,[0,2,7,24,...|\n",
      "|  0.0|07732584351 - Rod...|[07732584351, -, ...|(13587,[0,2,3,10,...|\n",
      "|  0.0|08714712388 betwe...|[08714712388, bet...|(13587,[353,387,8...|\n",
      "|  0.0|09066362231 URGEN...|[09066362231, urg...|(13587,[0,3,4,7,1...|\n",
      "|  0.0|0A$NETWORKS allow...|[0a$networks, all...|(13587,[0,3,10,16...|\n",
      "|  0.0|100 dating servic...|[100, dating, ser...|(13587,[224,665,7...|\n",
      "|  0.0|1000's flirting N...|[1000's, flirting...|(13587,[0,6,24,28...|\n",
      "|  0.0|1000's of girls m...|[1000's, of, girl...|(13587,[0,5,12,20...|\n",
      "|  0.0|18 days to Euro20...|[18, days, to, eu...|(13587,[0,4,5,6,1...|\n",
      "|  0.0|18 days to Euro20...|[18, days, to, eu...|(13587,[0,4,5,6,1...|\n",
      "|  0.0|1st wk FREE! Gr8 ...|[1st, wk, free!, ...|(13587,[0,5,10,16...|\n",
      "|  0.0|       2/2 146tf150p|    [2/2, 146tf150p]|(13587,[5831,5893...|\n",
      "|  0.0|22 days to kick o...|[22, days, to, ki...|(13587,[0,4,5,6,1...|\n",
      "|  0.0|25p 4 alfie Moon'...|[25p, 4, alfie, m...|(13587,[0,8,10,16...|\n",
      "|  0.0|3. You have recei...|[3., you, have, r...|(13587,[2,11,14,9...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into test and training data\n",
    "i=0\n",
    "data_train, data_test = clean_data.randomSplit([0.75,0.25],i)\n",
    "data_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'text',\n",
       " 'words',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "log_reg = LogisticRegression(maxIter = 10)\n",
    "\n",
    "paramgrid_log_reg = ParamGridBuilder() \\\n",
    "    .addGrid(log_reg.regParam, np.linspace(0.3, 0.01, 10)) \\\n",
    "    .addGrid(log_reg.elasticNetParam, np.linspace(0.3, 0.80, 6)) \\\n",
    "    .build()\n",
    "crossval_log_reg = CrossValidator(estimator=log_reg,\n",
    "                          estimatorParamMaps=paramgrid_log_reg,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds= 5)  \n",
    "cross_val_model_log_reg = crossval_log_reg.fit(data_train)\n",
    "best_model_log_reg = cross_val_model_log_reg.bestModel.summary\n",
    "best_model_log_reg.predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "bin_class = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "bin_class.evaluate(best_model_log_reg.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "mul_class = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "mul_class.evaluate(best_model_log_reg.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_class = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "mul_class.evaluate(best_model_log_reg.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0|  553|\n",
      "|  1.0|       1.0| 3594|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_data_train = best_model_log_reg.predictions.select('label','prediction')\n",
    "fit_data_train.groupBy('label','prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|                text|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(Bank of Granite ...|[(bank, of, grani...|(13587,[3,7,10,12...|[-4.0435855128697...|[0.01723232933579...|       1.0|\n",
      "|  0.0|2p per min to cal...|[2p, per, min, to...|(13587,[0,10,11,1...|[7.35214183781345...|[0.99935919339179...|       0.0|\n",
      "|  0.0|3 FREE TAROT TEXT...|[3, free, tarot, ...|(13587,[0,10,11,5...|[3.66606929116433...|[0.97506105109585...|       0.0|\n",
      "|  0.0|5 Free Top Polyph...|[5, free, top, po...|(13587,[0,3,15,34...|[2.97725530351675...|[0.95153595558103...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|[3.58582954630600...|[0.97303366766922...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|[3.58582954630600...|[0.97303366766922...|       0.0|\n",
      "|  0.0|74355 XMAS iscomi...|[74355, xmas, isc...|(13587,[0,20,28,5...|[6.87557237893499...|[0.99896835901214...|       0.0|\n",
      "|  0.0|83039 62735=£450 ...|[83039, 62735=£45...|(13587,[2,7,11,20...|[2.81837853674816...|[0.94366092334568...|       0.0|\n",
      "|  0.0|85233 FREE>Ringto...|[85233, free>ring...|(13587,[329,10723...|[-4.0233674729954...|[0.01757809253005...|       1.0|\n",
      "|  0.0|88066 FROM 88066 ...|[88066, from, 880...|(13587,[40,328,10...|[1.07137129783977...|[0.74485761127645...|       0.0|\n",
      "|  0.0|<Forwarded from 2...|[<forwarded, from...|(13587,[0,2,6,7,1...|[3.24384206210141...|[0.96245120429448...|       0.0|\n",
      "|  0.0|Adult 18 Content ...|[adult, 18, conte...|(13587,[2,11,30,3...|[-0.8456080260503...|[0.30035498509947...|       1.0|\n",
      "|  0.0|Am new 2 club & d...|[am, new, 2, club...|(13587,[5,20,28,3...|[1.47259805762691...|[0.81345195684813...|       0.0|\n",
      "|  0.0|As a SIM subscrib...|[as, a, sim, subs...|(13587,[0,2,3,4,1...|[0.36780239676232...|[0.59092785347613...|       0.0|\n",
      "|  0.0|BIG BROTHER ALERT...|[big, brother, al...|(13587,[4,5,10,15...|[3.13214400114841...|[0.95819935179054...|       0.0|\n",
      "|  0.0|Babe: U want me d...|[babe:, u, want, ...|(13587,[3,5,6,13,...|[-3.0295403241700...|[0.04610904074017...|       1.0|\n",
      "|  0.0|Back 2 work 2morr...|[back, 2, work, 2...|(13587,[1,5,13,14...|[-2.5524247926299...|[0.07226375443102...|       1.0|\n",
      "|  0.0|Block Breaker now...|[block, breaker, ...|(13587,[4,6,8,10,...|[-2.2824209206219...|[0.09258935496796...|       1.0|\n",
      "|  0.0|Bored of speed da...|[bored, of, speed...|(13587,[0,2,3,6,1...|[2.28156631643447...|[0.90733881911903...|       0.0|\n",
      "|  0.0|Bought one ringto...|[bought, one, rin...|(13587,[6,49,81,1...|[-1.7128271267657...|[0.15279738389234...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = cross_val_model_log_reg.transform(data_test)\n",
    "test_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|   41|\n",
      "|  0.0|       0.0|  153|\n",
      "|  1.0|       1.0| 1233|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.groupBy('label','prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712683952347583"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_acc = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "multi_class_acc.evaluate(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698059362766078"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_f1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "multi_class_f1.evaluate(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
